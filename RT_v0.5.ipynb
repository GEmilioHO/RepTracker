{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reprogramming Tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import cv2\n",
    "except ImportError:\n",
    "    !pip install opencv-python\n",
    "\n",
    "try:\n",
    "    import cellpose\n",
    "except ImportError:\n",
    "    !pip install cellpose\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import imgfileutils as imf\n",
    "from core import *\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from cellpose import utils, models, io, plot\n",
    "import skimage.io\n",
    "import numpy as np\n",
    "from skimage.measure import regionprops\n",
    "from math import pi\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "from plotly.subplots import make_subplots\n",
    "from skimage.filters import threshold_otsu, threshold_local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Create dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Get .CZI names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/volumes/emilio_passport/msc_neuro/lab/rep_tracker/data/d6Ngn2/d6Ngn2_V2/'     # Insert path to the folder with the CZI file\n",
    "path_fig = '/volumes/emilio_passport/msc_neuro/lab/rep_tracker/figures/d6Ngn2_Bleb/ppt/'     # Path to save generated images\n",
    "\n",
    "no_files = input('Single File or Multiple Files (S/M)? ')\n",
    "\n",
    "if no_files.lower() == 's':\n",
    "    ### --- File Name\n",
    "    for f in listdir(path): \n",
    "        if isfile(join(path, f)) and f.lower().endswith('.czi'):\n",
    "            print(f)\n",
    "    filename = input('Insert name of file + format (i.e.: file.czi): ')\n",
    "    dct[filename] = {}\n",
    "    dct[filename]['filename'] = filename\n",
    "    try:\n",
    "        ### --- Get the CZI object using the path + filename\n",
    "        dct[filename]['file_path'] = path + dct[filename]['filename']\n",
    "    except:\n",
    "        print('Invalid Filename!')\n",
    "elif no_files.lower() == 'm':\n",
    "    onlyfiles = [f for f in listdir(path) if isfile(join(path, f)) and f.lower().endswith('.czi')]\n",
    "    try:\n",
    "        onlyfiles.remove('.DS_Store')\n",
    "    except:\n",
    "        pass\n",
    "    for file in onlyfiles:\n",
    "        dct[file] = {}\n",
    "        ### --- Get the CZI object using the path + filename\n",
    "        dct[file]['filename'] = file\n",
    "        dct[file]['file_path'] = path + dct[file]['filename']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 Load .CZI files and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Read metadata and array differently for OME-TIFF or CZI data\n",
    "for file in dct:\n",
    "    if dct[file]['filename'].lower().endswith('.ome.tiff') or dct[file]['filename'].lower().endswith('.ome.tif'):\n",
    "\n",
    "        ### --- Return value is an array of order (T, Z, C, X, Y)\n",
    "        (dct[file]['array'], dct[file]['omexml']) = io.read_ometiff(dct[file]['file_path'])\n",
    "        dct[file]['metadata'], dct[file]['add_metadata'] = imf.get_metadata(dct[file]['file_path'], series = 0)\n",
    "\n",
    "    if dct[file]['filename'].lower().endswith('.czi'):\n",
    "        print(file)\n",
    "        ### --- Get the array and the metadata\n",
    "        dct[file]['array'], dct[file]['metadata'], dct[file]['add_metadata'] = imf.get_array_czi(dct[file]['file_path'], \n",
    "                                                                                                 return_addmd = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Obtain shapes and dimensions of array and metadata (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = True\n",
    "for file in dct:\n",
    "    if flag == True:\n",
    "        ### --- Shape of the numpy array\n",
    "        print('Array Shape: ', dct[file]['array'].shape)\n",
    "\n",
    "        ### --- Dimension order of the metadata\n",
    "        print('Dimension Order (BioFormats) : ', dct[file]['metadata']['DimOrder BF Array'])\n",
    "\n",
    "        ### --- Shape and dimension entry of the CZI file as returned by czifile.py\n",
    "        print('CZI Array Shape : ', dct[file]['metadata']['Shape'])\n",
    "        print('CZI Dimension Entry : ', dct[file]['metadata']['Axes'])\n",
    "        flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Show all the metadata (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = True\n",
    "for file in dct:\n",
    "    if flag == True:\n",
    "        for key, value in dct[file]['metadata'].items():\n",
    "            print(key, ' : ', value)     # print all key-value pairs for the dictionary\n",
    "        flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.0 Select working channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = True\n",
    "for file in dct:\n",
    "    ### --- Identify the content of each channel\n",
    "    dct[file]['channels'] = {}\n",
    "    \n",
    "    dct[file]['working_array'] = wk_array(dct[file]['array'], dct[file]['metadata']['Axes'])\n",
    "    \n",
    "    for channel in range(len(dct[file]['metadata']['Channels'])):\n",
    "        dct[file]['channels']['ch%s' % str(channel)] = dct[file]['working_array'][channel]\n",
    "        \n",
    "    if flag == True:\n",
    "        channel_nuclei, channel_induction_reporter, channel_reprogrammed, channel_gfap, __ = identify_channels(dct[file]['metadata']['Channels'])\n",
    "    flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.0 Segmentation of Nuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = input('Insert method for segmentation (cellpose OR classic): ')\n",
    "\n",
    "if method.lower() == 'classic':\n",
    "    \n",
    "    thresh_options = ['K-means', 'Otsu', 'Isodata', 'Li', 'Mean', 'Minimum',\n",
    "                      'Triangle', 'Yen', 'Sauvola', 'Adaptive_Otsu']\n",
    "    \n",
    "    for option in thresh_options:\n",
    "        print(option)\n",
    "        \n",
    "    thresh_option = input('Insert desired thresholding method: ')\n",
    "    \n",
    "for file in tqdm(dct):\n",
    "    for channel in dct[file]['channels']:\n",
    "        if channel == 'ch%s' % channel_nuclei:\n",
    "            if method.lower() == 'cellpose':\n",
    "                dct[file]['masks_%s' % channel], dct[file]['flows_%s' % channel] = segment_image_nuclei(\n",
    "                    dct[file]['channels'][channel], method = method, diameter = 30)\n",
    "            elif method.lower() == 'classic':\n",
    "                dct[file]['masks_%s' % channel] = segment_image_nuclei(dct[file]['channels'][channel], \n",
    "                                                                       method = method, \n",
    "                                                                       thresh_option = thresh_option, \n",
    "                                                                       name = dct[file]['filename'], \n",
    "                                                                       h_fraction = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Show nuclear segmentation (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for file in dct:\n",
    "    for channel in dct[file]['channels']:\n",
    "        if channel == 'ch%s' % channel_nuclei:\n",
    "            if method.lower() == 'cellpose':\n",
    "                channels = [0, 0]\n",
    "                fig = plt.figure(figsize = (12,5))\n",
    "                plot.show_segmentation(fig, dct[file]['channels'][channel], dct[file]['masks_%s' % channel], \n",
    "                                       dct[file]['flows_%s' % channel][0], channels = channels)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            elif method.lower() == 'classic':\n",
    "                plt.rcParams['figure.figsize'] = [30/2.54, 22.5/2.54]\n",
    "                plt.imshow(dct[file]['channels'][channel], 'gray')\n",
    "                masked = np.ma.masked_where(dct[file]['masks_%s' % channel] <= 0, dct[file]['masks_%s' % channel])\n",
    "                plt.imshow(masked, alpha = 0.8)\n",
    "                plt.title(dct[file]['filename'])\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.0 Obtain first set of nuclear parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for file in dct:\n",
    "    for channel in dct[file]['channels']:\n",
    "        if channel == 'ch%s' % channel_nuclei:\n",
    "            cell_no = []\n",
    "            nuclei_area = []\n",
    "            nuclei_intensity = []\n",
    "            circularities = []\n",
    "            nuclei_perimeter = []\n",
    "            eccentricities = []\n",
    "            solidities = []\n",
    "            major_axes = []\n",
    "            minor_axes = []\n",
    "            axes_ratios = []\n",
    "            xpos = []\n",
    "            ypos = []\n",
    "            props = regionprops(dct[file]['masks_%s' % channel], intensity_image = dct[file]['channels'][channel])\n",
    "            for p in props:\n",
    "                if p['label'] > 0:\n",
    "                    \n",
    "                    cell_no.append(p['label'])\n",
    "                    \n",
    "                    area = p['area'] * (float(dct[file]['metadata']['XScale']) * float(dct[file]['metadata']['YScale']))\n",
    "                    nuclei_area.append(round(area))\n",
    "                    \n",
    "                    nuclei_intensity.append(round(p['mean_intensity']))\n",
    "                    \n",
    "                    perimeter = p['perimeter'] * dct[file]['metadata']['XScale']\n",
    "                    nuclei_perimeter.append(round(p['perimeter']))\n",
    "                    \n",
    "                    circularity = 4 * pi * (area / perimeter ** 2)\n",
    "                    circularities.append(round(circularity, 3))\n",
    "                    \n",
    "                    eccentricities.append(round(p['eccentricity'], 3))\n",
    "                    \n",
    "                    solidities.append(round(p['solidity'], 3))\n",
    "                    \n",
    "                    major_axis = p['major_axis_length'] * dct[file]['metadata']['XScale']\n",
    "                    major_axes.append(round(major_axis, 1))\n",
    "                    \n",
    "                    minor_axis = p['minor_axis_length'] * dct[file]['metadata']['XScale']\n",
    "                    minor_axes.append(round(minor_axis, 1))                  \n",
    "\n",
    "                    axes_ratio = minor_axis / major_axis\n",
    "                    axes_ratios.append(round(axes_ratio, 3))\n",
    "                    \n",
    "                    cY, cX = p['centroid']\n",
    "                    xpos.append(round(cX))\n",
    "                    ypos.append(round(cY))\n",
    "                    \n",
    "    dct_df = {'cell_no': cell_no, 'nucleus_intensity': nuclei_intensity, 'nucleus_area': nuclei_area, \n",
    "             'nucleus_perimeter': nuclei_perimeter, 'major_axis': major_axes, 'minor_axis': minor_axes,\n",
    "             'axes_ratio': axes_ratios, 'circularity': circularities, 'eccentricity': eccentricities,\n",
    "             'solidity': solidities, 'x_pos': xpos, 'y_pos': ypos}\n",
    "\n",
    "    dct[file]['df'] = pd.DataFrame(data = dct_df)\n",
    "    \n",
    "    fig = go.Figure(go.Table(header = dict(values = ['Cell<br>Number', 'Nuclear<br>Intensity', 'Nuclear<br>Area<br>(µm2)', \n",
    "                                                     'Nucleus<br>Perimeter<br>(µm)', 'Major<br>Axis<br>(µm)', \n",
    "                                                     'Minor<br>Axis<br>(µm)',\n",
    "                                                     'Axes<br>Ratio', 'Circularity', 'Eccentricity', \n",
    "                                                     'Solidity', 'x pos', 'y pos'], \n",
    "                                           align = 'left'), \n",
    "                             cells = dict(values = [dct[file]['df'][k].tolist() for k in dct[file]['df'].columns[0:]], align = 'left')))\n",
    "    fig.update_layout(title = dct[file]['filename'].split('.')[0])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Show distribution of nuclear area and intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_nuc_area = []\n",
    "x_int = []\n",
    "\n",
    "for file in dct:\n",
    "    for v in dct[file]['df']['nucleus_area']:\n",
    "        x_nuc_area.append(v)\n",
    "    for v in dct[file]['df']['nucleus_intensity']:\n",
    "        x_int.append(v)\n",
    "        \n",
    "fig = make_subplots(rows = 2, cols = 1, shared_xaxes = True)\n",
    "fig.add_trace(go.Box(x = x_nuc_area, boxpoints = 'suspectedoutliers', fillcolor = 'rgba(7,40,89,0.5)', \n",
    "                     line_color = 'rgb(7,40,89)', showlegend = False, name = ''), row = 1, col = 1)\n",
    "fig.add_trace(go.Histogram(x = x_nuc_area, histnorm = 'probability', marker_color = 'rgb(7,40,89)',\n",
    "                          name = 'Area', showlegend = False), row = 2, col = 1)\n",
    "fig.update_layout(title = \"Distribution of Cells' Nucleus Area\", \n",
    "                  xaxis = dict(autorange = True, showgrid = True, zeroline = True, gridwidth=1), width = 1000, \n",
    "                  height = 400, template = \"plotly_white\")\n",
    "fig.show()\n",
    "#fig.write_image(path_fig + 'area_hist_bp.pdf')\n",
    "\n",
    "\n",
    "fig = make_subplots(rows = 2, cols = 1, shared_xaxes = True)\n",
    "fig.add_trace(go.Box(x = x_int, boxpoints = 'suspectedoutliers', fillcolor = 'rgba(8,81,156,0.5)', \n",
    "                     line_color = 'rgb(8,81,156)', showlegend = False, name = ''), row = 1, col = 1)\n",
    "fig.add_trace(go.Histogram(x = x_int, histnorm = 'probability', marker_color = 'rgb(8,81,156)',\n",
    "                          name = 'Intensity', showlegend = False), row = 2, col = 1)\n",
    "fig.update_layout(title = \"Distribution of Cells' Nuclei Intensity\", \n",
    "                  xaxis = dict(autorange = True, showgrid = True, zeroline = True, gridwidth=1), width = 1000, \n",
    "                  height = 400, template = \"plotly_white\")\n",
    "fig.show()\n",
    "#fig.write_image(path_fig + 'intensity_hist_bp.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.0 Apply filters to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_area_filter = input('Enter an UPPER threshold for nuclei area (µm2): ')\n",
    "min_area_filter = input('Enter a LOWER threshold for nuclei area (µm2): ')\n",
    "circularity_filter = input('Enter an LOWER threshold for nuclei circularity: ')\n",
    "intensity_filter = input('Enter an LOWER threshold for nuclei intensity: ')\n",
    "\n",
    "for file in dct:\n",
    "    dct[file]['df_filtered'] = dct[file]['df']\n",
    "    to_be_removed = dct[file]['df_filtered'].index[dct[file]['df_filtered']['nucleus_area'] > int(max_area_filter)].tolist()\n",
    "    to_be_removed += dct[file]['df_filtered'].index[dct[file]['df_filtered']['nucleus_area'] < int(min_area_filter)].tolist()\n",
    "    to_be_removed += dct[file]['df_filtered'].index[dct[file]['df_filtered']['circularity'] < float(circularity_filter)].tolist()\n",
    "    to_be_removed += dct[file]['df_filtered'].index[dct[file]['df_filtered']['nucleus_intensity'] < int(intensity_filter)].tolist()\n",
    "    to_be_removed = np.array(to_be_removed)\n",
    "    to_be_removed = np.unique(to_be_removed).tolist()\n",
    "    dct[file]['df_filtered'] = dct[file]['df_filtered'].drop(to_be_removed)\n",
    "    dct[file]['df_filtered'].reset_index(drop = True, inplace = True)\n",
    "\n",
    "    fig = go.Figure(go.Table(header = dict(values = ['Cell<br>Number', 'Nuclear<br>Intensity', 'Nuclear<br>Area<br>(µm2)', \n",
    "                                                     'Nucleus<br>Perimeter<br>(µm)', 'Major<br>Axis<br>(µm)', \n",
    "                                                     'Minor<br>Axis<br>(µm)',\n",
    "                                                     'Axes<br>Ratio', 'Circularity', 'Eccentricity', \n",
    "                                                     'Solidity', 'x pos', 'y pos'], \n",
    "                                           align = 'left'), \n",
    "                             cells = dict(values = [dct[file]['df_filtered'][k].tolist() for k in dct[file]['df_filtered'].columns[0:]], \n",
    "                                          align = 'left')))\n",
    "    fig.update_layout(title = dct[file]['filename'].split('.')[0])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Show new data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = True\n",
    "for file in dct:\n",
    "    if flag == False:\n",
    "        temp_df = temp_df.append(dct[file]['df_filtered'])\n",
    "    if flag == True:\n",
    "        temp_df = dct[file]['df_filtered'].copy()\n",
    "        flag = False\n",
    "    \n",
    "fig = px.density_heatmap(temp_df, x = 'nucleus_area', y = 'nucleus_intensity', marginal_x = 'histogram', \n",
    "                         marginal_y = 'histogram', color_continuous_scale = px.colors.diverging.RdYlBu_r,\n",
    "                         nbinsx = 15, nbinsy = 15)\n",
    "fig.show()\n",
    "#fig.write_image(path_fig + 'intensityVSarea_hm.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.0 Image thresholding for other channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_options = ['K-means', 'Otsu', 'Isodata', 'Li', 'Mean', 'Minimum',\n",
    "                  'Triangle', 'Yen', 'Sauvola', 'Adaptive_Otsu']\n",
    "\n",
    "for option in thresh_options:\n",
    "    print(option)\n",
    "\n",
    "thresh_option = input('Insert desired thresholding method: ')\n",
    "    \n",
    "for file in dct:\n",
    "    for channel in dct[file]['channels']:\n",
    "        if channel != 'ch%s' % channel_nuclei:\n",
    "            dct[file]['thresh_%s' % (channel)] = thresholding(dct[file]['channels'][channel], dct[file]['filename'],\n",
    "                                                             thresh_option)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Generate binary images of the other channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in dct:\n",
    "    for channel in dct[file]['channels']:\n",
    "        if channel != 'ch%s' % channel_nuclei:\n",
    "            dct[file]['closing_%s' % (channel)] = binary_img(dct[file]['thresh_%s' % (channel)], \n",
    "                                                             dct[file]['filename'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.0 Identify cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in dct:\n",
    "    for channel in dct[file]['channels']:\n",
    "        if channel == 'ch%s' % channel_nuclei:\n",
    "            cell_type = assign_celltype(df = dct[file]['df_filtered'], \n",
    "                                        binary_rfp = dct[file]['closing_ch%s' % (channel_induction_reporter)], \n",
    "                                        binary_b3 = dct[file]['closing_ch%s' % (channel_reprogrammed)], \n",
    "                                        mask_nuclei = dct[file]['masks_%s' % channel], \n",
    "                                        col_cells = 'cell_no')\n",
    "            dct_df = {'cell_type': cell_type}\n",
    "            df_add = pd.DataFrame(data = dct_df)\n",
    "            dct[file]['df_celltype'] = pd.concat([dct[file]['df_filtered'], df_add], axis = 1, sort = True)\n",
    "            fig = go.Figure(go.Table(header = dict(values = ['Cell<br>Number', 'Nuclear<br>Intensity', 'Nuclear<br>Area<br>(µm2)', \n",
    "                                                             'Nucleus<br>Perimeter<br>(µm)', 'Major<br>Axis<br>(µm)', \n",
    "                                                             'Minor<br>Axis<br>(µm)',\n",
    "                                                             'Axes<br>Ratio', 'Circularity', 'Eccentricity', \n",
    "                                                             'Solidity', 'x pos', 'y pos', 'Cell<br>Type'], \n",
    "                                                   align = 'left'), \n",
    "                                     cells = dict(values = [dct[file]['df_celltype'][k].tolist() for k in dct[file]['df_celltype'].columns[0:]], \n",
    "                                                  align = 'left')))\n",
    "            fig.update_layout(title = dct[file]['filename'].split('.')[0])\n",
    "            fig.show()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.0 Obtain second set of nuclear parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for file in dct:\n",
    "    hc_no = []\n",
    "    hc_inner = []\n",
    "    hc_outer = []\n",
    "    hc_edge = []\n",
    "    intensity_inner = []\n",
    "    intensity_outer = []\n",
    "    intensity_edge = []\n",
    "    intensity_rfp = []\n",
    "    intensity_b3 = []\n",
    "    sum_int_b3_edges = []\n",
    "    intensity_gfap = []\n",
    "    sum_int_nuclei = []\n",
    "    sum_int_inners = []\n",
    "    sum_int_outers = []\n",
    "    sum_int_edges = []\n",
    "    for channel in dct[file]['channels']:\n",
    "        if channel == 'ch%s' % channel_nuclei:\n",
    "            for cell in tqdm(dct[file]['df_celltype']['cell_no']):\n",
    "                dots, dots_inner, dots_outer, dots_edge = find_hcdots(dct[file]['channels'][channel], \n",
    "                                                                      dct[file]['masks_%s' % channel], \n",
    "                                                                      cell_no = cell, \n",
    "                                                                      xscale = float(dct[file]['metadata']['XScale']))\n",
    "                hc_no.append(dots)\n",
    "                hc_inner.append(dots_inner)\n",
    "                hc_outer.append(dots_outer)\n",
    "                hc_edge.append(dots_edge)\n",
    "                \n",
    "                int_inner, int_outer, int_edge, __ = find_intesities_layers(dct[file]['channels'][channel], \n",
    "                                                                           dct[file]['masks_%s' % channel], \n",
    "                                                                           cell_no = cell, \n",
    "                                                                           xscale = float(dct[file]['metadata']['XScale']))\n",
    "                intensity_inner.append(int_inner)\n",
    "                intensity_outer.append(int_outer)\n",
    "                intensity_edge.append(int_edge)\n",
    "                \n",
    "                sum_int_nucleus, sum_int_inner, sum_int_outer, sum_int_edge = sum_intensities(dct[file]['channels'][channel], \n",
    "                                                                                              dct[file]['masks_%s' % channel], \n",
    "                                                                                              cell_no = cell,\n",
    "                                                                                              xscale = float(dct[file]['metadata']['XScale']))\n",
    "                \n",
    "                sum_int_nuclei.append(sum_int_nucleus)               \n",
    "                sum_int_inners.append(sum_int_inner)               \n",
    "                sum_int_outers.append(sum_int_outer)               \n",
    "                sum_int_edges.append(sum_int_edge)\n",
    "                \n",
    "                int_rfp = find_intensity(dct[file]['channels']['ch%s' % (channel_induction_reporter)], \n",
    "                                         dct[file]['masks_%s' % channel], \n",
    "                                         cell_no = cell)\n",
    "                intensity_rfp.append(int_rfp)\n",
    "\n",
    "                int_b3 = find_intensity(dct[file]['channels']['ch%s' % (channel_reprogrammed)], \n",
    "                                         dct[file]['masks_%s' % channel], \n",
    "                                         cell_no = cell)\n",
    "                intensity_b3.append(int_b3)\n",
    "\n",
    "                __, __, __, sum_int_edge_b3 = sum_intensities(dct[file]['channels']['ch%s' % (channel_reprogrammed)], \n",
    "                                                                                              dct[file]['masks_%s' % channel], \n",
    "                                                                                              cell_no = cell,\n",
    "                                                                                              xscale = float(dct[file]['metadata']['XScale']))\n",
    "                \n",
    "                sum_int_b3_edges.append(sum_int_edge_b3)\n",
    "                \n",
    "                __, __, __, int_gfap = find_intesities_layers(dct[file]['channels']['ch%s' % (channel_gfap)], \n",
    "                                                              dct[file]['masks_%s' % channel],\n",
    "                                                              cell_no = cell,\n",
    "                                                              xscale = float(dct[file]['metadata']['XScale']))\n",
    "                intensity_gfap.append(int_gfap)\n",
    "                \n",
    "            dct_df = {'hc_no': hc_no, 'hc_inner': hc_inner, 'hc_outer': hc_outer, 'hc_edge': hc_edge,\n",
    "                     'intensity_inner': intensity_inner, 'intensity_outer': intensity_outer, \n",
    "                     'intensity_edge': intensity_edge, 'sum_int_nucleus': sum_int_nuclei,\n",
    "                      'sum_int_inner': sum_int_inners, 'sum_int_outer': sum_int_outers,\n",
    "                      'sum_int_edge': sum_int_edges, 'intensity_rfp': intensity_rfp, \n",
    "                     'intensity_b3': intensity_b3, 'sum_int_b3_edges': sum_int_b3_edges,\n",
    "                      'intensity_gfap': intensity_gfap}\n",
    "            \n",
    "            df_add = pd.DataFrame(data = dct_df)\n",
    "            dct[file]['df_final'] = pd.concat([dct[file]['df_celltype'], df_add], axis = 1, sort = True)\n",
    "            \n",
    "            fig = go.Figure(go.Table(header = dict(values = ['Cell<br>Number', 'Cell<br>Type', 'Hc Dots', \n",
    "                                                            'Hc Dots<br>Inner', 'Hc Dots<br>Outer',\n",
    "                                                            'Hc Dots<br>Edge', 'Int<br>Inner', 'Int<br>Outer',\n",
    "                                                            'Int<br>Edge', 'Sum<br>Int<br>Nucleus',\n",
    "                                                             'Sum<br>Int<br>Inner','Sum<br>Int<br>Outer',\n",
    "                                                             'Sum<br>Int<br>Edge','Int<br>RFP', 'Int<br>B3',\n",
    "                                                             'Sum<br>Int<br>B3<br>Edge',\n",
    "                                                             'Int<br>GFAP'], \n",
    "                                                   align = 'left'), \n",
    "                                     cells = dict(values = [dct[file]['df_final'][k].tolist() for k in dct[file]['df_final'].columns[np.r_[0, 12:27]]], \n",
    "                                                  align = 'left')))\n",
    "            fig.update_layout(title = dct[file]['filename'].split('.')[0])\n",
    "            fig.show()            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in dct:\n",
    "    dct[file]['df_final']['source'] = [str(file.split('.')[0]) for n in range(len(dct[file]['df_final']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.0 Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "from pathlib import Path\n",
    "\n",
    "if len(dct) == 1:\n",
    "    out_file = filename.split('.')[0] + '.csv'    # Change name of output file\n",
    "    command = input('Do you want to create NEW file or APPEND to existing file (new/append)? ')\n",
    "\n",
    "    my_file = Path(path + out_file)\n",
    "\n",
    "    try:\n",
    "        if command.lower() == 'new':\n",
    "            df_final.to_csv(my_file)\n",
    "        elif command.lower() == 'append':\n",
    "            if my_file.is_file():\n",
    "                df_final.to_csv(my_file, mode = 'a', header = False)\n",
    "            else:\n",
    "                df_final.to_csv(my_file)\n",
    "        filename_save = filename.split('.')[0]\n",
    "        scipy.io.savemat(path + filename_save + '_masks.mat', mdict = {'out': dct['markers_ch%s' % channel_nuclei]})\n",
    "        scipy.io.savemat(path + filename_save + '_nuclei.mat', mdict = {'out': channels['ch%s' % channel_nuclei]})\n",
    "        print('Successfully saved!')\n",
    "    except:\n",
    "        print('Ops! An error occurred...')\n",
    "elif len(dct) > 1:\n",
    "    save_s_m = input('Save as Single or Multiple Files (S/M)? ')\n",
    "    if save_s_m.lower() == 'm':\n",
    "        for file in dct:\n",
    "            out_file = dct[file]['filename'].split('.')[0] + '.csv'    # Change name of output file\n",
    "\n",
    "            my_file = Path(path + out_file)\n",
    "\n",
    "            try:\n",
    "                dct[file]['df_final'].to_csv(my_file)\n",
    "                scipy.io.savemat(path + dct[file]['filename'].split('.')[0] + '_binary_gfap.mat', mdict = {'out': dct[file]['closing_ch%s' % channel_gfap]})\n",
    "                scipy.io.savemat(path + dct[file]['filename'].split('.')[0] + '_gfap.mat', mdict = {'out': dct[file]['channels']['ch%s' % channel_gfap]})\n",
    "                scipy.io.savemat(path + dct[file]['filename'].split('.')[0] + '_binary_rfp.mat', mdict = {'out': dct[file]['closing_ch%s' % channel_induction_reporter]})\n",
    "                scipy.io.savemat(path + dct[file]['filename'].split('.')[0] + '_rfp.mat', mdict = {'out': dct[file]['channels']['ch%s' % channel_induction_reporter]})\n",
    "                scipy.io.savemat(path + dct[file]['filename'].split('.')[0] + '_binary_b3.mat', mdict = {'out': dct[file]['closing_ch%s' % channel_reprogrammed]})\n",
    "                scipy.io.savemat(path + dct[file]['filename'].split('.')[0] + '_b3.mat', mdict = {'out': dct[file]['channels']['ch%s' % channel_reprogrammed]})\n",
    "                scipy.io.savemat(path + dct[file]['filename'].split('.')[0] + '_masks.mat', mdict = {'out': dct[file]['masks_ch%s' % channel_nuclei]})\n",
    "                scipy.io.savemat(path + dct[file]['filename'].split('.')[0] + '_nuclei.mat', mdict = {'out': dct[file]['channels']['ch%s' % channel_nuclei]})\n",
    "                print(dct[file]['filename'].split('.')[0], 'Successfully saved!')\n",
    "            except:\n",
    "                print('Ops! An error occurred...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
